{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt > ../.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspotipy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspotipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moauth2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpotifyClientCredentials\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisper'"
     ]
    }
   ],
   "source": [
    "# from google.cloud import speech_v1p1beta1 as speech\n",
    "import io\n",
    "import openai \n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import time\n",
    "import whisper\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from pytube import YouTube\n",
    "import os\n",
    "import whisper\n",
    "import tempfile\n",
    "import ollama\n",
    "import ssl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_api_keys(file_path):\n",
    "    api_keys = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            key, value = line.strip().split('=')\n",
    "            api_keys[key] = value.strip('\"')\n",
    "    return api_keys\n",
    "\n",
    "# Path to the .api-key file\n",
    "api_key_file_path = '../data/.api_keys'\n",
    "\n",
    "# Read and parse the .api-key file\n",
    "api_keys = read_api_keys(api_key_file_path)\n",
    "\n",
    "# Access the API keys\n",
    "assemblyai_api_key = api_keys.get('assemblyai')\n",
    "openai_api_key = api_keys.get('openai_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio to text\n",
    "def transcribe_audio_assemblyai(audio_file_path):\n",
    "    api_key = assemblyai_api_key\n",
    "    headers = {\n",
    "        'authorization': api_key,\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Upload the audio file\n",
    "    upload_url = 'https://api.assemblyai.com/v2/upload'\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        response = requests.post(upload_url, headers=headers, files={'file': audio_file})\n",
    "    audio_url = response.json()['upload_url']\n",
    "\n",
    "    # Request transcription\n",
    "    transcript_url = 'https://api.assemblyai.com/v2/transcript'\n",
    "    transcript_request = {\n",
    "        'audio_url': audio_url\n",
    "    }\n",
    "    response = requests.post(transcript_url, headers=headers, json=transcript_request)\n",
    "    transcript_id = response.json()['id']\n",
    "\n",
    "    # Poll for transcription result\n",
    "    while True:\n",
    "        response = requests.get(f'{transcript_url}/{transcript_id}', headers=headers)\n",
    "        result = response.json()\n",
    "        if result['status'] == 'completed':\n",
    "            return result['text']\n",
    "        elif result['status'] == 'failed':\n",
    "            raise Exception('Transcription failed')\n",
    "        time.sleep(5)\n",
    "\n",
    "def search_song_lyrics(lyrics, access_token):\n",
    "    base_url = \"https://api.genius.com\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "    search_url = f\"{base_url}/search\"\n",
    "    params = {\"q\": lyrics}\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    response_data = response.json()\n",
    "    \n",
    "    if response.status_code == 200 and response_data['response']['hits']:\n",
    "        song_info = response_data['response']['hits'][0]['result']\n",
    "        song_title = song_info['title']\n",
    "        artist_name = song_info['primary_artist']['name']\n",
    "        return song_title, artist_name\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def transcribe_audio_openai(audio_file_path):\n",
    "    # Initialize the client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    # Upload and transcribe the audio file\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    # Extract and return the transcription\n",
    "    return response.text\n",
    "\n",
    "# Transcribe audio to text using local Whisper model\n",
    "def transcribe_audio_local(audio_file_path):\n",
    "    model = whisper.load_model(\"base\")  # or \"tiny\", \"small\", \"medium\", \"large\"\n",
    "    result = model.transcribe(audio_file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def identify_song_from_lyrics(lyrics):\n",
    "    # Initialize the client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    # Create the prompt\n",
    "    prompt = f\"Identify the song from the following lyrics:\\n\\n{lyrics}\\n\\nSong name:\"\n",
    "    # Make the API call using the new format\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    # Extract and return the response\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Identify song from lyrics using Spotify API\n",
    "def identify_song_from_lyrics_spotify(lyrics, client_id, client_secret):\n",
    "    sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
    "    results = sp.search(q=lyrics, type='track', limit=1)\n",
    "    if results['tracks']['items']:\n",
    "        track = results['tracks']['items'][0]\n",
    "        song_name = track['name']\n",
    "        artist_name = track['artists'][0]['name']\n",
    "        return song_name, artist_name\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def search_song_lyrics_musixmatch(lyrics, api_key):\n",
    "    api_key = 'your_musixmatch_api_key'\n",
    "    base_url = \"https://api.musixmatch.com/ws/1.1/\"\n",
    "    search_url = f\"{base_url}track.search\"\n",
    "    params = {\n",
    "        \"q_lyrics\": lyrics,\n",
    "        \"apikey\": api_key,\n",
    "        \"s_track_rating\": \"desc\",\n",
    "        \"f_has_lyrics\": 1,\n",
    "        \"page_size\": 1,\n",
    "        \"page\": 1\n",
    "    }\n",
    "    response = requests.get(search_url, params=params)\n",
    "    response_data = response.json()\n",
    "    \n",
    "    if response.status_code == 200 and response_data['message']['header']['status_code'] == 200:\n",
    "        track_list = response_data['message']['body']['track_list']\n",
    "        if track_list:\n",
    "            track = track_list[0]['track']\n",
    "            song_name = track['track_name']\n",
    "            artist_name = track['artist_name']\n",
    "            return song_name, artist_name\n",
    "    return None, None\n",
    "\n",
    "# Main function\n",
    "def main(audio_file_path):\n",
    "    # lyrics = transcribe_audio_assemblyai(audio_file_path)\n",
    "    lyrics = transcribe_audio_openai(audio_file_path)\n",
    "    # lyrics = \"Shut up. Yes, please. Won't you come on me? I'm right here. Cause I need somebody.\"\n",
    "    # lyrics = transcribe_audio_local(audio_file_path)\n",
    "    print(\"Extracted Lyrics:\", lyrics)\n",
    "    # song_name = identify_song_from_lyrics(lyrics)\n",
    "    # print(\"Identified Song Name:\", song_name)\n",
    "\n",
    "    # # Identify song from lyrics using Spotify API\n",
    "    # # song_name, artist_name = identify_song_from_lyrics_spotify(lyrics, client_id, client_secret)\n",
    "    # # song_name, artist_name = search_song_lyrics_musixmatch(lyrics, api_key)\n",
    "    # if song_name and artist_name:\n",
    "    #     print(f\"Identified Song Name: {song_name} by {artist_name}\")\n",
    "    # else:\n",
    "    #     print(\"Could not identify the song.\")\n",
    "    # if song_name and artist_name:\n",
    "    #     print(f\"Identified Song Name: {song_name} by {artist_name}\")\n",
    "    # else:\n",
    "    #     print(\"Could not identify the song.\")\n",
    "\n",
    "# Replace with the path to your audio file\n",
    "audio_file_path = \"../data/track_audio.mp3\"\n",
    "client_id = 'your_spotify_client_id'\n",
    "client_secret = 'your_spotify_client_secret'\n",
    "main(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/music/lib/python3.12/site-packages/whisper.py\n",
      "Error processing video: module 'whisper' has no attribute 'load_model'\n"
     ]
    }
   ],
   "source": [
    "# Disable SSL verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def recognize_music_from_youtube(youtube_url):\n",
    "    try:\n",
    "        # Create a temporary directory to store the audio file\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "\n",
    "            # # Download audio from YouTube\n",
    "            # yt = YouTube(youtube_url)\n",
    "            # audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "            \n",
    "            # # Download to temporary file\n",
    "            # temp_audio_path = os.path.join(temp_dir, 'temp_audio.mp4')\n",
    "            # audio_stream.download(output_path=temp_dir, filename='temp_audio.mp4')\n",
    "\n",
    "            temp_audio_path = \"../data/easy.mp3\"\n",
    "\n",
    "            # Transcribe the audio file using Whisper \n",
    "            print(whisper.__file__)\n",
    "            model = whisper.load_model(\"base\")  # or \"tiny\", \"small\", \"medium\", \"large\"\n",
    "            result = model.transcribe(temp_audio_path)\n",
    "            transcription = result[\"text\"]\n",
    "\n",
    "            print(\"Transcription:\", transcription)\n",
    "            \n",
    "            # transcription = \"Your sugar, yes, please Won't you come and put it down on me?  I'm right here, 'cause I need Little love, a little sympathy Yeah, you show me good lovin', make it alright Need a little sweetness in my life Your sugar, yes, please Won't you come and put it down on me?\"\n",
    "\n",
    "            # Now use the transcription to identify the song\n",
    "            prompt = f\"Based on these lyrics or audio transcription, what song is this? If it's a song, please provide the song name and artist. If it's not a song, please indicate that it's not music. Here's the transcription:\\n\\n{transcription}\"\n",
    "            \n",
    "            # # Initialize the OpenAI client\n",
    "            # openai.api_key = 'your_openai_api_key'\n",
    "            # response = openai.ChatCompletion.create(\n",
    "            #     model=\"gpt-3.5-turbo\",\n",
    "            #     messages=[\n",
    "            #         {\"role\": \"system\", \"content\": \"You are a music expert. Identify songs based on lyrics or transcribed audio content.\"},\n",
    "            #         {\"role\": \"user\", \"content\": prompt}\n",
    "            #     ]\n",
    "            # )\n",
    "\n",
    "             # Use Ollama to recognize the song\n",
    "            prompt = f\"Identify the song based on these lyrics:\\n\\n{transcription}\\n\\nProvide the song name and artist.\"\n",
    "            response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "            return response['message']['content'].strip()\n",
    "            \n",
    "            # return response.choices[0].message['content'].strip()\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error processing video: {str(e)}\"\n",
    "\n",
    "# Example usage:\n",
    "result = recognize_music_from_youtube(\"https://www.youtube.com/watch?v=YOUR_VIDEO_ID\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze | sed 's/ @ file:.*//' > ../requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
